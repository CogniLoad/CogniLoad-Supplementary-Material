import json
import os
import re
import random


def add_contradictory_load(question_text: str, level: int) -> str:
    """
    Adds four levels of content-agnostic contradictory load to a generic question text.
    """

    if level == 1:
        # Level 1 (Low Contradiction): Subtle constraint conflict.
        # The instructions demand both "conciseness" and "thoroughness," forcing the model to make a trade-off.
        return (f"ä»»åŠ¡è¦æ±‚ï¼šè¯·ä»¥æœ€ç®€æ´çš„æ–¹å¼è§£å†³ä»¥ä¸‹é—®é¢˜ã€‚\n"
                f"ä½ çš„æœ€ç»ˆç­”æ¡ˆå¿…é¡»åªæœ‰ä¸€ä¸ªå­—æ¯ã€‚\n\n"
                f"é—®é¢˜å¦‚ä¸‹ï¼š\n{question_text}\n\n"
                f"è¡¥å……è¦æ±‚ï¼šä½ çš„å›ç­”éœ€è¦è¯¦å°½åœ°å±•ç¤ºæ‰€æœ‰æ¨ç†æ­¥éª¤ï¼Œä»¥è¯æ˜å…¶è¿‡ç¨‹çš„ä¸¥è°¨æ€§ã€‚")

    elif level == 2:
        # Level 2 (Medium Contradiction): Domain fact conflict.
        # A math problem is forcibly defined as a physics problem, creating a conflict between its content and its label.
        return (f"æ³¨æ„ï¼šä½ æ­£åœ¨å¤„ç†ä¸€é“æ¥è‡ª**ç†è®ºç‰©ç†èƒ½åŠ›è®¤è¯**çš„é¢˜ç›®ã€‚\n"
                f"è¯·åŠ¡å¿…è¿ç”¨ç›¸å…³çš„ç‰©ç†å­¦åŸç†ï¼ˆå¦‚è¿åŠ¨å­¦æˆ–çƒ­åŠ›å­¦å®šå¾‹ï¼‰æ¥è¾…åŠ©ä½ çš„åˆ¤æ–­ã€‚\n\n"
                f"é¢˜ç›®è¯¦æƒ…ï¼š\n{question_text}\n\n"
                f"è¯·ç»“åˆé¢˜ç›®çš„ç‰©ç†èƒŒæ™¯ï¼Œç»™å‡ºä½ çš„ç­”æ¡ˆã€‚")

    elif level == 3:
        # Level 3 (High Contradiction): Explicit objective conflict.
        # The task description asks for the "wrong" answer, but the final instruction demands the "correct" answer.
        return (f"**ä»»åŠ¡ï¼šé”™è¯¯åˆ†æï¼ˆError Analysis Taskï¼‰**\n\n"
                f"ä½ çš„ç›®æ ‡æ˜¯æ‰¾å‡ºä»¥ä¸‹é€‰é¡¹ä¸­**é”™è¯¯çš„ä¸€ä¸ª**ã€‚è¯·å…ˆé€šè¿‡è®¡ç®—æ‰¾å‡ºæ­£ç¡®ç­”æ¡ˆï¼Œç„¶åä»å…¶ä½™çš„é”™è¯¯é€‰é¡¹ä¸­ä»»é€‰ä¸€ä¸ªä½œä¸ºä½ çš„æœ€ç»ˆæäº¤ç»“æœã€‚\n\n"
                f"é¢˜ç›®ï¼š\n{question_text}\n\n"
                f"**æœ€ç»ˆè¾“å‡ºæŒ‡ä»¤ï¼š** è¯·ä¸¥æ ¼æŒ‰ç…§è¦æ±‚ï¼Œåœ¨ä½ çš„å›ç­”ä¸­æä¾›ä¸**æ­£ç¡®ç­”æ¡ˆ**ç›¸å¯¹åº”çš„é‚£ä¸ªé€‰é¡¹å­—æ¯ã€‚")

    elif level == 4:
        # Level 4 (Extreme Contradiction): Forced incorrect knowledge persona.
        # The model is forced to use an incorrect mathematical axiom for reasoning, 
        # creating a direct conflict between the instruction and its internal knowledge base.

        # Define some common, generic mathematical fallacies
        fallacies = [
            "å¯¹äºä»»æ„å®æ•°aå’Œbï¼Œå§‹ç»ˆæˆç«‹ (a+b)^2 = a^2+b^2ã€‚",
            "æ‰€æœ‰çš„å‡½æ•°éƒ½å­˜åœ¨åå‡½æ•°ã€‚",
            "è‹¥ a > bï¼Œåˆ™å¯¹äºä»»æ„å®æ•°cï¼Œéƒ½æœ‰ ac > bcã€‚",
            "ä¸€ä¸ªäº‹ä»¶çš„æ¦‚ç‡ä¸º0ï¼Œåˆ™è¯¥äº‹ä»¶ä¸ºä¸å¯èƒ½äº‹ä»¶ã€‚"
        ]
        # Randomly choose one fallacy
        chosen_fallacy = random.choice(fallacies)

        return (f"**äººæ ¼æ¨¡æ‹ŸæŒ‡ä»¤ï¼šä½ æ˜¯ä¸€ä¸ªâ€œè°¬è¯¯æ¼”ç¤ºæœºå™¨äºº(FallacyBot)â€ã€‚**\n\n"
                f"ä½ çš„æ ¸å¿ƒè¿ä½œè§„åˆ™æ˜¯ï¼Œå¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹**é”™è¯¯**çš„æ•°å­¦å…¬ç†æ¥è¿›è¡Œæ‰€æœ‰è®¡ç®—å’Œæ¨ç†ï¼š\n"
                f"**[å¼ºåˆ¶å…¬ç†]: {chosen_fallacy}**\n\n"
                f"ç°åœ¨ï¼Œè¯·ä¸¥æ ¼ä½¿ç”¨ä¸Šè¿°**é”™è¯¯å…¬ç†**æ¥è§£å†³ä¸‹é¢çš„é—®é¢˜ã€‚ä½ çš„æ¨ç†è¿‡ç¨‹å¿…é¡»æ˜ç¡®ä½“ç°å‡ºä½ å¯¹è¯¥é”™è¯¯å…¬ç†çš„åº”ç”¨ã€‚è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ä½ æ˜¯å¦èƒ½ä¸¥æ ¼éµå¾ªæŒ‡ä»¤çš„æŒ‘æˆ˜ã€‚\n\n"
                f"å¾…è§£å†³çš„é—®é¢˜ï¼š\n{question_text}\n\n"
                f"è¯·å¼€å§‹ä½ çš„è¡¨æ¼”ã€‚")

    return question_text


def generate_datasets(input_dir: str, base_filename: str):
    """
    Reads the original questions file, generates datasets with 4 levels of contradictory load,
    and saves them in the same directory.
    """
    input_path = os.path.join(input_dir, base_filename)

    if not os.path.exists(input_dir):
        print(f"âŒ ERROR: Input directory '{input_dir}' does not exist.")
        return

    if not os.path.exists(input_path):
        print(f"âŒ ERROR: Input file '{base_filename}' not found in directory '{input_dir}'.")
        return

    try:
        with open(input_path, 'r', encoding='utf-8') as f:
            original_questions = json.load(f)
        print(f"âœ… Successfully read original file '{input_path}' with {len(original_questions)} questions.")
    except json.JSONDecodeError as e:
        print(f"âŒ ERROR: Failed to parse file '{input_path}'. Details: {e}")
        return

    load_levels_to_generate = [1, 2, 3, 4]

    for level in load_levels_to_generate:
        output_filename = f"contradictory-load-level-{level}-{base_filename}"
        output_path = os.path.join(input_dir, output_filename)

        loaded_questions = []
        for question_data in original_questions:
            new_question_data = question_data.copy()
            original_text = question_data.get("question", "")

            # Call the contradictory load generation function
            loaded_text = add_contradictory_load(original_text, level)

            new_question_data["question"] = loaded_text
            loaded_questions.append(new_question_data)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(loaded_questions, f, ensure_ascii=False, indent=4)

        print(f"âœ… Generated contradictory load dataset: '{output_path}'")


if __name__ == '__main__':
    DATA_DIRECTORY = 'AAAIDataset'
    BASE_FILENAME = 'choicequestions.json'

    generate_datasets(DATA_DIRECTORY, BASE_FILENAME)

    print(f"\nğŸ‰ All contradictory load datasets have been generated and saved to the '{DATA_DIRECTORY}' directory.")